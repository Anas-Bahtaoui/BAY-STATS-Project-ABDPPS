{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7621e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES. BE SURE NOT TO OVERWRITE THEM\n",
    "D = 8 # Amount of documents\n",
    "V = 12 # Size of the vocabulary\n",
    "\n",
    "# (Approximate) Maximum allowed amount of same word repetition in a document (it may be lower in practise due to the data generation strategy)\n",
    "# To get the actual maximum amount, call Simulator.get_M\n",
    "M = 10 \n",
    "\n",
    "k = 5 # Amount of topics\n",
    "gamma = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0f161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GLOBAL VARIABLES. BE SURE NOT TO OVERWRITE THEM\n",
    "# D = 100 # Amount of documents\n",
    "# V = 20 # Size of the vocabulary\n",
    "\n",
    "# # (Approximate) Maximum allowed amount of same word repetition in a document (it may be lower in practise due to the data generation strategy)\n",
    "# # To get the actual maximum amount, call Simulator.get_M\n",
    "# M = 10 \n",
    "\n",
    "# k = 10 # Amount of topics\n",
    "# gamma = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa52dd2",
   "metadata": {},
   "source": [
    "## IMPORTANT: Please use static random seeds in **EVERY** cell where you use a random function, so that the result does **NOT** change at every run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82ceed5",
   "metadata": {},
   "source": [
    "# 1. ARTIFICIAL DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab978d52",
   "metadata": {},
   "source": [
    "### Task:\n",
    "\n",
    "You must implement an algorithm that generates an artificial *corpus*, and return also a graph G and a correlation matrix Sigma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed16817d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_93608/1643984072.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbernoulli\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#!pip install sklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_sparse_spd_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import bernoulli\n",
    "#!pip install sklearn\n",
    "from sklearn.datasets import make_sparse_spd_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fb1c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation functions (deterministic)\n",
    "\n",
    "def update_Theta(Theta, H):\n",
    "    for d in range(D):\n",
    "        Theta[d] = np.exp(H[d]) / np.sum(np.exp(H[d]), axis=0)\n",
    "    print('Success: Theta transformed from H')\n",
    "    return Theta\n",
    "\n",
    "def update_E(E, Z):\n",
    "    k = E.shape[1]\n",
    "    for topic in range(k):\n",
    "        E[:, topic] = np.sum(Z == topic, axis=2).sum(axis=1)\n",
    "    print('Success: E transformed from Z')\n",
    "    return E\n",
    "\n",
    "def update_C(C, Z):\n",
    "    k = C.shape[0]\n",
    "    for topic in range(k):\n",
    "        C[topic, :] = np.sum(Z == topic, axis=2).sum(axis=0)\n",
    "    print('Success: C transformed from Z')\n",
    "    return C\n",
    "\n",
    "def update_B(B, C):\n",
    "    # Note this is the transformation from C\n",
    "    for topic in range(0, len(B)):\n",
    "        B[topic] = C[topic] / sum(C[topic])\n",
    "    print('Success: B transformed from C')\n",
    "    return B\n",
    "\n",
    "def update_Sigma(K):\n",
    "    Sigma = np.linalg.inv(K)\n",
    "    print('Success: Sigma transformed from K')\n",
    "    return Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92478222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random / Generating functions\n",
    "\n",
    "def build_topic_distribution(seed):\n",
    "    np.random.seed(seed)\n",
    "    distribution = np.random.random(V)\n",
    "    return distribution / distribution.sum()\n",
    "\n",
    "def sample_B(seed):\n",
    "    # B is the matrix whose rows are the distribution of topic i over the vocabulary\n",
    "    # Each row means : for each topic i we have the probability of word i to occur\n",
    "    # TODO: Change with Dirichlet prior -> See line to change\n",
    "    b = np.empty((k,V))\n",
    "    np.random.seed(seed)\n",
    "    for i in range(k):\n",
    "        b[i,:] = build_topic_distribution(seed)  # TODO: Change\n",
    "    return b\n",
    "\n",
    "def sample_G(k, gamma, seed):  # Won't update Sigma automatically anymore\n",
    "    # Bernoulli for G\n",
    "    # generate a random adjacency matrix\n",
    "    np.random.seed(seed)\n",
    "    matrix = np.array([[int(bernoulli.rvs(p=gamma, size=1)) for i in range(k)] for j in range(k)])\n",
    "    for i in range(k):\n",
    "        matrix[i][i] = 0\n",
    "    for i in range(k):\n",
    "        for j in range(k):\n",
    "            matrix[j][i] = matrix[i][j]\n",
    "    return matrix\n",
    "\n",
    "def sample_K(k, seed):  # Won't update Sigma automatically anymore\n",
    "    # I can build K for using make_sparse_spd_matrix from sklearn.datasets for example\n",
    "    np.random.seed(seed)\n",
    "    K = make_sparse_spd_matrix(k, alpha=0.95, norm_diag=False, smallest_coef=0.1, largest_coef=0.9, random_state=None)\n",
    "    return K\n",
    "\n",
    "def sample_H(Sigma, D, k, seed):  # Won't update Theta automatically anymore\n",
    "    # Multivariate Normal\n",
    "    mu = np.zeros(k)\n",
    "    np.random.seed(seed)\n",
    "    H = np.random.multivariate_normal(mu, Sigma, D)\n",
    "    return H\n",
    "\n",
    "def sample_Z_from_W(W, k, seed):\n",
    "    D, V = W.shape\n",
    "    M = int(W.max())\n",
    "    Z = -np.ones((D, V, M))\n",
    "    np.random.seed(seed)\n",
    "    for d in range(D):\n",
    "        for w in range(V): \n",
    "            occurrences = W[d, w]\n",
    "            Z[d, w, 0:occurrences] = np.random.randint(0, k, size=occurrences)    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d05436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Simulator Class\n",
    "class Simulator:\n",
    "    \n",
    "    # Remember we will have indexes starting from 0 so all max are -=1\n",
    "    \n",
    "    def __init__(self, D, V, M, k, gamma, seed):\n",
    "        # Create zero matrices for all possible matrices\n",
    "        self.W = np.zeros((D, V))  # matrix of DÃ—V where Wdn is counter of appearances of the word n in document d\n",
    "        self.B = np.zeros((k, V))  # matrix of kxV where Bz is the parameter vector of the distribution for the z-th topic\n",
    "        self.C = np.zeros((k, V))  # matrix of kxV where Cz is the count vec of sampled topics over each word for all docs\n",
    "        self.E = np.zeros((D, k))  # matrix of Dxk where Ed is the count vec of sampled drawings for topic z over all words for each doc\n",
    "        self.H = np.zeros((D, k))  # H_d is eta_d\n",
    "        self.Theta = np.zeros((D, k))  # This is just a transformation of H\n",
    "        self.G = np.zeros((k, k))  # Adjacency Matrix (Check also python package \"networkx\" for graph objects!)\n",
    "        self.K = np.zeros((k, k))  # Precision matrix of G\n",
    "        self.Sigma = np.zeros((k, k))  # Inverse of K\n",
    "        self.Z = -np.ones((D, V, M))  # Topic assignments for each words of each document\n",
    "        self.D = D\n",
    "        self.V = V\n",
    "        self.M = M\n",
    "        self.k = k\n",
    "        self.gamma = gamma\n",
    "        self.seed = seed  # Random seed\n",
    "        \n",
    "#     def get_M(self):\n",
    "#         # Ref: https://numpy.org/doc/stable/reference/generated/numpy.matrix.max.html\n",
    "#         return int(self.W.max())\n",
    "\n",
    "    # Generations\n",
    "    def generate_WZ(self):\n",
    "        if M == 0:\n",
    "            raise Exception('Error: M value is 0')\n",
    "        elif np.sum(self.Theta, axis=1).sum(axis=0) == 0:\n",
    "            raise Exception('Error: Theta matrix 0')\n",
    "        elif np.sum(self.B, axis=1).sum(axis=0) == 0:\n",
    "            raise Exception('Error: B matrix 0')\n",
    "        \n",
    "        np.random.seed(self.seed)\n",
    "        # Ref https://numpy.org/doc/stable/reference/random/generated/numpy.random.multinomial.html\n",
    "        # Multinomial drawing for Z and then W\n",
    "        for d in range(self.D):\n",
    "            \n",
    "            # Maximum number of word drawings in the document            \n",
    "            N_d = np.random.randint(1, int(self.M * self.V * 0.7))  # Hard-coding 70% thinning factor\n",
    "            for n in range(N_d):\n",
    "                \n",
    "                # Multinomial drawing from Theta, because it has to be normalized\n",
    "                # This will give a canonical vector over k\n",
    "                mult = np.random.multinomial(1, self.Theta[d], size=1)  # This is a vector of 0's with a single 1\n",
    "                z = np.argmax(mult)  # This is the index of the 1 (Topic index)\n",
    "                \n",
    "                # Multinomial drawing from Beta\n",
    "                # This will give a canonical vector over V\n",
    "                mult = np.random.multinomial(1, self.B[z], size=1)  # This is a vector of 0's with a single 1\n",
    "                w = np.argmax(mult)  # This is the index of the 1 (Word index)\n",
    "                \n",
    "                empty_cell_indexes = np.nonzero(self.Z[d, w] == -1)[0]  # Check if there are still possible unassigned occurrences for this word\n",
    "                if empty_cell_indexes.size != 0:  # At least one entry is not assigned\n",
    "                    first_empty_index = empty_cell_indexes[0]\n",
    "                    self.Z[d, w, first_empty_index] = z  # Assinging word to topic\n",
    "                    self.W[d, w] += 1  # Increasing word counter\n",
    "        \n",
    "        print('Success: W and Z generated')\n",
    "\n",
    "        # TODO: I have replaced this function in order to have the exact M\n",
    "#     # Generations\n",
    "#     def generate_WZ(self):\n",
    "#         if M == 0:\n",
    "#             raise Exception('Error: M value is 0')\n",
    "#         elif np.sum(self.Theta, axis=1).sum(axis=0) == 0:\n",
    "#             raise Exception('Error: Theta matrix 0')\n",
    "#         elif np.sum(self.B, axis=1).sum(axis=0) == 0:\n",
    "#             raise Exception('Error: B matrix 0')\n",
    "        \n",
    "#         Z = [[[] for k in range(self.V)] for j in range(self.D)]  # Unknown amount of repetitions\n",
    "#         np.random.seed(self.seed)\n",
    "#         # Ref https://numpy.org/doc/stable/reference/random/generated/numpy.random.multinomial.html\n",
    "#         # Multinomial drawing for Z and then W\n",
    "#         for d in range(self.D):\n",
    "#             # Maximum of words in the document: Lower int of 70% of M * V\n",
    "#             N_d = np.random.randint(0, (5 * self.M * self.V) // 10)\n",
    "#             for n in range(N_d):\n",
    "                \n",
    "#                 # Multinomial drawing from Theta, because it has to be normalized\n",
    "#                 # This will give a canonical vector over k\n",
    "#                 mult = np.random.multinomial(1, self.Theta[d], size=1)  # This is a vector of 0's with a single 1\n",
    "#                 z = np.argmax(mult)  # This is the index of the 1 (Topic index)\n",
    "                \n",
    "#                 # Multinomial drawing from Beta\n",
    "#                 # This will give a canonical vector over V\n",
    "#                 mult = np.random.multinomial(1, self.B[z], size=1)  # This is a vector of 0's with a single 1\n",
    "#                 w = np.argmax(mult)  # This is the index of the 1 (Word index)\n",
    "                \n",
    "#                 Z[d][w].append(z)\n",
    "#                 self.W[d,w] += 1\n",
    "        \n",
    "#         print('Success: W generated')\n",
    "#         self.Z = - np.ones((self.D, self.V, self.get_M()))\n",
    "#         for d in range(self.D):\n",
    "#             for n in range(self.V):\n",
    "#                 for i in range(len(Z[d][n])):  # Only take existing topics\n",
    "#                     self.Z[d][n][i] = Z[d][n][i]  # Replace\n",
    "#         print('Success: Z generated')\n",
    "    \n",
    "    # Transformations\n",
    "    def update_Theta(self):\n",
    "        self.Theta = update_Theta(self.Theta, self.H)\n",
    "    \n",
    "    def update_E(self):\n",
    "        self.E = update_E(self.E, self.Z)\n",
    "    \n",
    "    def update_C(self):\n",
    "        self.C = update_C(self.C, self.Z)\n",
    "    \n",
    "    def update_Sigma(self):\n",
    "        self.Sigma = update_Sigma(self.K)\n",
    "    \n",
    "    # Initializing with real data\n",
    "    # def save_W()\n",
    "    \n",
    "    # Priors\n",
    "    def sample_B(self):\n",
    "        self.B = sample_B(self.seed)\n",
    "        \n",
    "    def sample_GK(self):  # Here we can update Sigma automatically\n",
    "        self.G = sample_G(self.k, self.gamma, self.seed)\n",
    "        self.K = sample_K(self.k, self.seed)\n",
    "        self.update_Sigma()\n",
    "    \n",
    "    def sample_H(self):  # Here we can update Theta automatically\n",
    "        self.H = sample_H(self.Sigma, self.D, self.k, self.seed)\n",
    "        self.update_Theta()\n",
    "    \n",
    "    def generate_all_data(self):\n",
    "        # TODO: This should run all relevant methods one after the other in order to fully populate all data matrixes\n",
    "        self.sample_B()  # Will get B\n",
    "        self.sample_GK()  # Will get G, K, Sigma\n",
    "        self.sample_H()  # Will get H, Theta from Sigma\n",
    "        self.generate_WZ()  # Will get W, Z from Theta, B\n",
    "        self.update_E()  # Will get E from Z\n",
    "        self.update_C()  # Will get C from Z\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71043c2",
   "metadata": {},
   "source": [
    "## 1.1 Simulator Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880fbef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test0 = Simulator(D, V, M, k, gamma, seed=1996)\n",
    "test0.sample_GK()  # Will get G, K, Sigma\n",
    "test0.sample_H()  # Will get H, Theta from Sigma\n",
    "test0.sample_B()  # Will get B\n",
    "test0.generate_WZ()\n",
    "test0.update_E()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03341020",
   "metadata": {},
   "outputs": [],
   "source": [
    "test0.W\n",
    "\n",
    "# NOTE:\n",
    "# With M*D it's not really respected that M is the real max, just a desired one\n",
    "# With 70% of that it's still not respected but closer\n",
    "#Â With 50% of that it's respected in this case -> Could check if we can have real max M at some point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c80e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All in one function\n",
    "test1 = Simulator(D, V, M, k, gamma, seed=1979)\n",
    "test1.generate_all_data()\n",
    "test1.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1becad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming that with the same seed and input parameters, data generated are the same\n",
    "test2 = Simulator(D, V, M, k, gamma, seed=1979)\n",
    "test2.generate_all_data()\n",
    "assert np.all(np.equal(test1.W, test2.W))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85474ef1",
   "metadata": {},
   "source": [
    "From now on let's use the following simulated data for further testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ba6870",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = Simulator(D, V, M, k, gamma, seed=1967)  # Man on the moon\n",
    "test_data.generate_all_data()\n",
    "\n",
    "random_initial_data = Simulator(D, V, M, k, gamma, seed=1969)  # Woodstock Music Festival\n",
    "random_initial_data.generate_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308b938b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "099a948c",
   "metadata": {},
   "source": [
    "# 2 MC SAMPLER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90423680",
   "metadata": {},
   "source": [
    "## 2.1.1 MCMC Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d375c5",
   "metadata": {},
   "source": [
    "### Task:\n",
    "\n",
    "You must implement a function that receives matrices $W$, $\\Theta_{i+1}$ and $B_i$ and generates the next $Z_{i+1}$ and $B_{i+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a9fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(sequence, item):\n",
    "    begin_index = 0\n",
    "    end_index = len(sequence)-1\n",
    "    \n",
    "    if sequence[begin_index] <= item and item <= sequence[end_index]:\n",
    "        while begin_index < end_index - 1:  # Finish when the list has 2 items: Begin and end\n",
    "            midpoint = (end_index + begin_index) // 2\n",
    "            midpoint_value = sequence[midpoint]\n",
    "            if midpoint_value < item:\n",
    "                begin_index = midpoint\n",
    "            else:\n",
    "                end_index = midpoint\n",
    "        if sequence[begin_index] == item:\n",
    "            return begin_index + 1\n",
    "        elif item <= sequence[end_index]:\n",
    "            return end_index\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a61f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC_sample_Z(Z, W, Theta, B, E, C):  # D, k are global variables\n",
    "    for d in range(D):\n",
    "        for v in range(V):\n",
    "            I_di = int(W[d, v])\n",
    "            for j in range(I_di):\n",
    "                z_hat = int(Z[d, v, j])\n",
    "                \n",
    "                E[d, z_hat] = max(0, E[d, z_hat]-1)\n",
    "                \n",
    "                C[z_hat, v] = max(0, C[z_hat, v]-1)\n",
    "                \n",
    "                Rho = []  # Needs to start from zero to have the interval to fall into topic 1\n",
    "                Rho_z = 0\n",
    "                Rho.append(Rho_z)\n",
    "                \n",
    "                for z in range(k):\n",
    "                    # Compute the denominator sum\n",
    "                    C_vk = 0\n",
    "                    for b in range(V):\n",
    "                        if b != v:\n",
    "                            C_vk += C[z, b]\n",
    "                    # Compute the upper limits of the topic probabilities\n",
    "                    d_part = E[d, z] + Theta[d, z]\n",
    "                    z_part = C[z, v] + B[z, v]\n",
    "                    denom = C_vk + V * B[z, v]\n",
    "                    Rho_z += d_part * z_part / denom\n",
    "                    Rho.append(Rho_z)\n",
    "                \n",
    "                u = np.random.uniform(0, Rho[-1])\n",
    "                z_hat = binary_search(Rho, u) - 1\n",
    "                \n",
    "                E[d, z_hat] += 1\n",
    "                C[z_hat, v] += 1\n",
    "                Z[d, v, j] = z_hat\n",
    "                \n",
    "    # Note that we directly modify Z since the update per topic helps for the next iteration \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fb1639",
   "metadata": {},
   "source": [
    "## 2.1.2 MCMC Sampling Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b862bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the function runs with no issues, without side effects but on Z\n",
    "Z_copy = random_initial_data.Z.copy()\n",
    "\n",
    "W_copy = test_data.W.copy()\n",
    "Theta_copy = test_data.Theta.copy()\n",
    "B_copy = test_data.B.copy()\n",
    "E_copy = test_data.E.copy()\n",
    "C_copy = test_data.C.copy()\n",
    "\n",
    "Z_sample = MC_sample_Z(Z_copy, W_copy, Theta_copy, B_copy, E_copy, C_copy)\n",
    "\n",
    "assert np.any(Z_copy != random_initial_data.Z)\n",
    "assert np.all(W_copy == test_data.W)\n",
    "assert np.all(Theta_copy == test_data.Theta)\n",
    "assert np.all(B_copy == test_data.B)\n",
    "\n",
    "# TODO: Review! Should these matrix change?  # BUG https://trello.com/c/pWZCzOxq/29-mcsamplez-e-and-c-are-modified\n",
    "# assert np.all(E_copy == test_data.E)\n",
    "# assert np.all(C_copy == test_data.C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Check that the Sampler works properly (This will take a while)\n",
    "errors = []\n",
    "matrix_changes = []\n",
    "burn_in = 1000\n",
    "print(f'The sampled Z has {Z_sample.size} words, while the target Z has {test_data.Z.size} words (diff {abs(Z_sample.size-test_data.Z.size)})')\n",
    "for i in range(5000):\n",
    "    Z_sample_old = Z_sample.copy()\n",
    "    Z_sample = MC_sample_Z(Z_sample, W_copy, Theta_copy, B_copy, E_copy.copy(), C_copy.copy())\n",
    "    matrix_changes.append(~np.all(Z_sample_old == Z_sample))\n",
    "    if i >= burn_in:\n",
    "        errors.append(np.linalg.norm(Z_sample - test_data.Z))  # Computing error wrt the target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5b0f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix should change\n",
    "matrix_changes = pd.Series(matrix_changes).astype(int)\n",
    "print(\"Matrix changes (1 = changed, 0 = same)\")\n",
    "print(matrix_changes.describe())\n",
    "matrix_changes.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3d6830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error should be distributed close to 0 (I guess...)  # BUG https://trello.com/c/JE1T7Hur/31-mcsamplez-z-is-not-close-to-the-expected-target\n",
    "errors = pd.Series(errors)\n",
    "print(\"Error metrics\")\n",
    "print(errors.describe())\n",
    "errors.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a46d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45302993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9daa662d",
   "metadata": {},
   "source": [
    "## 2.2.1 Beta sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da77a6",
   "metadata": {},
   "source": [
    "### Task:\n",
    "\n",
    "You must implement a function that receives matrices $C_i$ and vector $\\alpha$ and generates the next $B_{i+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7908d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC_sample_B(alpha, C):\n",
    "    B = np.random.dirichlet(alpha + C[0,:], size=1)\n",
    "    for k in range(C.shape[0]):\n",
    "        B = np.concatenate((B, np.random.dirichlet(alpha + C[k,:], size=1)), axis=0)\n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a4e6d0",
   "metadata": {},
   "source": [
    "## 2.2.2 Beta sampling tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c705a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the function runs with no issues, without side effects\n",
    "alpha = np.ones(V)\n",
    "C_copy = test_data.C.copy()\n",
    "\n",
    "B_sample = MC_sample_B(alpha, C_copy)\n",
    "\n",
    "assert np.all(C_copy == test_data.C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbca3dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Check that the Sampler works properly (This will take a while)\n",
    "errors = []\n",
    "matrix_changes = []\n",
    "burn_in = 1000\n",
    "print(f'The sampled B has {B_sample.size} words, while the target B has {test_data.B.size} words (diff {abs(B_sample.size-test_data.B.size)})')\n",
    "for i in range(5000):\n",
    "    B_sample_old = B_sample.copy()\n",
    "    B_sample = MC_sample_B(alpha, C_copy)\n",
    "    matrix_changes.append(~np.all(B_sample_old == B_sample))\n",
    "    if i >= burn_in:\n",
    "        errors.append(np.linalg.norm(B_sample - test_data.B))  # Computing error wrt the target distribution  # BUG https://trello.com/c/uEYV7fSC/32-mcsampleb-shape-mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f2e113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix should change\n",
    "matrix_changes = pd.Series(matrix_changes).astype(int)\n",
    "print(\"Matrix changes (1 = changed, 0 = same)\")\n",
    "print(matrix_changes.describe())\n",
    "matrix_changes.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a9dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error should be distributed close to 0 (I guess...)  # BUG https://trello.com/c/JE1T7Hur/31-mcsamplez-z-is-not-close-to-the-expected-target\n",
    "errors = pd.Series(errors)\n",
    "print(\"Error metrics\")\n",
    "print(errors.describe())\n",
    "errors.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7d04b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee34d6e3",
   "metadata": {},
   "source": [
    "## 2.3.1 Metropolis-Hastings MC Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b1732f",
   "metadata": {},
   "source": [
    "### Task:\n",
    "\n",
    "You must implement a function that receives matrices $E_i$, $K_i$ and vector $\\mu$ and generates the next $H_{i+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9de520",
   "metadata": {},
   "source": [
    "\n",
    ". $E$ matrix of $D \\times k$ where $E_d$ is the $k$-dim vector of counts of sampled drawings for the $z$-th topic over all words for each document\n",
    "\n",
    ". $K$ matrix of $k \\times k$ representing the precision matrix associated to the graph $G$\n",
    "\n",
    ". $\\mu = 0$\n",
    "\n",
    ". $H$ matrix of $D \\times k$ where $H_d = \\eta_d$ is the $k$-dim vector of the topic prevalences over document $d$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1044509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d2ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampled_distribution_kernel(eta, K, E):\n",
    "    k = eta.shape[0]\n",
    "    eta_K_eta = -0.5 * eta.dot(K.dot(eta))\n",
    "    E_eta = E.dot(eta)\n",
    "    sum_eta_pow_k = np.sum(np.exp(eta)) ** k\n",
    "    return np.exp(eta_K_eta + E_eta) / sum_eta_pow_k  # This np.exp raises a warning when  eta_K_eta + E_eta > 706"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8832139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC_sample_H(E, Sigma, H_current=None, burn_in=100, seed=None):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    K = np.linalg.inv(Sigma)\n",
    "    \n",
    "    D, k = E.shape  # Number of documents, Number of topics\n",
    "    \n",
    "    if H_current is None:\n",
    "        H_current = np.zeros((D, k))\n",
    "    \n",
    "    H_sampled = np.zeros((D, k))\n",
    "    \n",
    "    for d in range(D):  # Iterating over each document\n",
    "        current_eta = H_current[d]\n",
    "        E_d = E[d]\n",
    "        for iteration in range(burn_in + 1):\n",
    "            \n",
    "            # Sampling proposed eta from multivariate normal (q \"proposal density\")\n",
    "            proposed_eta = np.random.multivariate_normal(current_eta, Sigma)\n",
    "            \n",
    "            # Compute acceptance probability\n",
    "            p_proposed_eta = sampled_distribution_kernel(proposed_eta, K, E_d)\n",
    "            p_current_eta = sampled_distribution_kernel(current_eta, K, E_d)\n",
    "            if p_proposed_eta == np.inf or p_current_eta == 0:  # Avoiding divide by 0 and other numerical creeps\n",
    "                alpha = 1\n",
    "            else:\n",
    "                alpha = min(1, p_proposed_eta / p_current_eta)\n",
    "            \n",
    "            if alpha == 1 or np.random.uniform(0.0, 1.0) < alpha:\n",
    "                current_eta = proposed_eta\n",
    "            \n",
    "        H_sampled[d] = current_eta\n",
    "    \n",
    "    return H_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a330456",
   "metadata": {},
   "source": [
    "## 2.3.2 MH Sampling Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed54b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_copy = test_data.E.copy()\n",
    "Sigma_copy = test_data.Sigma.copy()\n",
    "\n",
    "H_sample = MC_sample_H(E_copy, Sigma_copy)\n",
    "\n",
    "assert np.all(E_copy == test_data.E)\n",
    "assert np.all(Sigma_copy == test_data.Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f806d849",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Check that the Sampler works properly (This will take... forever)\n",
    "errors = []\n",
    "matrix_changes = []\n",
    "burn_in = 1000\n",
    "for i in range(5000):\n",
    "    H_sample_old = H_sample.copy()\n",
    "    H_sample = MC_sample_H(E_copy, Sigma_copy, burn_in=1)\n",
    "    matrix_changes.append(~np.all(H_sample_old == H_sample))\n",
    "    if i >= burn_in:\n",
    "        errors.append(np.linalg.norm(H_sample - test_data.H))  # Computing error wrt the target matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8974020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix should change\n",
    "matrix_changes = pd.Series(matrix_changes).astype(int)\n",
    "print(\"Matrix changes (1 = changed, 0 = same)\")\n",
    "print(matrix_changes.describe())\n",
    "matrix_changes.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c405f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error should be distributed close to 0 (I guess...)  # BUG https://trello.com/c/9k2e8PQz/33-mcsampleh-is-not-close-to-expected-target\n",
    "errors = pd.Series(errors)\n",
    "print(\"Error metrics\")\n",
    "print(errors.describe())\n",
    "errors.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11e790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4465b490",
   "metadata": {},
   "source": [
    "## 2.4.1 BDMCMC Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a346b06",
   "metadata": {},
   "source": [
    "### Task:\n",
    "\n",
    "You must implement a function that receives matrices $W$, $Z_{i+1}$ and $H_{i+1}$ and generates the next $G_{i+1}$ and $K_{i+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaad057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Remember to install BDgraph package version 2.62 on your R environment\n",
    "# You'll need to run the following commands:\n",
    "# remove.packages(\"BDgraph\")\n",
    "# install.packages(\"remotes\")\n",
    "# library(remotes)\n",
    "# install_version(\"BDgraph\", \"2.62\")\n",
    "\n",
    "\n",
    "def MC_sample_K(G, b, shape_matrix, n_of_samples, debug=False):\n",
    "    # save G to csv\n",
    "    np.savetxt(\"adj.csv\", G, delimiter=\",\")\n",
    "    # save shape_matrix to csv (OR pass them as parameters to RScript)\n",
    "    np.savetxt(\"shape.csv\", shape_matrix, delimiter=\",\")\n",
    "    # call R script using python.subprocess\n",
    "    result = subprocess.run(f\"Rscript --vanilla rgwish.R {b} {n_of_samples} {'TRUE' if debug else 'FALSE'}\", shell=True) # -> HOW MANY SAMPLES ARE REQUIRED? SHOULD THIS ALSO BE VARIABLE AND THEREFORE PASSED TO R?\n",
    "    if result.returncode != 0:\n",
    "        raise Exception(\"Rscript error! Check the previous logs for more details\")\n",
    "\n",
    "    # read the results from csv (OR get the result back from R script)\n",
    "    \n",
    "    # Always better to open file handlers within a \"with\" statement (otherwise you must take care of closing the file)\n",
    "    with open(\"gwish.csv\", \"r\") as csv_file:  \n",
    "        K = np.loadtxt(csv_file, delimiter=\",\")\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9f1806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC_sample_G(W, Z, H, K, G, E, dof, shape):\n",
    "\n",
    "    N = G.shape[0]\n",
    "    delta_K = 0\n",
    "    beta_K = 0\n",
    "\n",
    "    death_rates = np.zeros((k,k))\n",
    "    birth_rates = np.zeros((k,k))\n",
    "    \n",
    "    n = D  # It's either of the shape indices of H\n",
    "    # from the paper I'm not sure yet which but looks the docs for us\n",
    "    \n",
    "    S = shape  # prior parameter\n",
    "    b = dof  # prior parameter\n",
    "\n",
    "    PrHK = lambda K, H:        K.size ** (n / 2) * np.exp(-0.5 * np.trace(np.matmul(np.matmul(K, H.T), H)))\n",
    "    PrK_G = lambda K, G, D, b: K.size ** (b + D - 2) * np.exp(-0.5 * np.trace(np.matmul(S + np.matmul(H.T, H), K)))\n",
    "    PrG = lambda gamma, E:  (gamma / (1 - gamma)) ** (E.size)\n",
    "    PrKG_H = lambda K, G, H, D, b, gamma, E: PrHK(K, H) * PrK_G(K, G, D, b) * PrG(gamma, E)\n",
    "\n",
    "    Pr_init = PrKG_H(K, G, H, D, k - 1, gamma, E)\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(i + 1, N):\n",
    "            if G[i,j]:\n",
    "                G_loop = G.copy()\n",
    "                G_loop[i,j] = 0\n",
    "                G_loop[j,i] = 0\n",
    "                #technically, we should compute K_loop here...\n",
    "                Pr_loop = PrKG_H(K,G_loop,H,D,b,gamma,E)\n",
    "\n",
    "                death_rate = Pr_loop / Pr_init\n",
    "\n",
    "                if death_rate > 1:\n",
    "                    death_rate = 1\n",
    "                death_rates[i,j] = death_rate\n",
    "                death_rates[j,i] = death_rate\n",
    "                delta_K += death_rate\n",
    "\n",
    "            else:\n",
    "                G_loop = G.copy()\n",
    "                G_loop[i,j] = 1\n",
    "                G_loop[j,i] = 1\n",
    "                #technically, we should compute K_loop here...\n",
    "                Pr_loop = PrKG_H(K, G_loop, H, D, b, gamma, E) \n",
    "\n",
    "                birth_rate = Pr_loop / Pr_init\n",
    "\n",
    "                if birth_rate > 1:\n",
    "                    birth_rate = 1\n",
    "                birth_rates[i,j] = birth_rate\n",
    "                birth_rates[j,i] = birth_rate\n",
    "                beta_K += birth_rate\n",
    "    \n",
    "    W = 1/(beta_K + delta_K)\n",
    "\n",
    "    pr_death = W * death_rates\n",
    "    pr_birth = W * birth_rates\n",
    "\n",
    "    G[pr_death > 0.5] = 0\n",
    "    G[pr_birth > 0.5] = 1\n",
    "   \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5406a43b",
   "metadata": {},
   "source": [
    "## 2.4.2 BDMCMC Sampling Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd3986f",
   "metadata": {},
   "source": [
    "#### MC_sample_K tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3b9b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a basic test of MC_sample_K\n",
    "G = [[0,0,1,0,0],\n",
    "    [0,0,0,0,0],\n",
    "    [1,0,0,0,0],\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,0,0,0]]\n",
    "shape_matrix = np.eye(5, dtype=int)\n",
    "K_sample = MC_sample_K(G, 5, shape_matrix, n_of_samples=1)\n",
    "\n",
    "assert np.all(shape_matrix == np.eye(5, dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8174472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a basic test of MC_sample_K\n",
    "G_copy = test_data.G.copy()\n",
    "shape_matrix = np.eye(k, dtype=int)\n",
    "b = k - 1\n",
    "K_sample = MC_sample_K(G_copy, b, shape_matrix, n_of_samples=1, debug=True)\n",
    "\n",
    "assert np.all(G_copy == test_data.G)\n",
    "assert np.all(shape_matrix == np.eye(k, dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ce7ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Check that the Sampler works properly (This will take... forever)\n",
    "errors = []\n",
    "matrix_changes = []\n",
    "burn_in = 0\n",
    "for i in range(1000):\n",
    "    K_sample_old = K_sample.copy()\n",
    "    K_sample = MC_sample_K(G_copy, b, shape_matrix, n_of_samples=1, debug=False)\n",
    "    matrix_changes.append(~np.all(K_sample_old == K_sample))\n",
    "    if i >= burn_in:\n",
    "        errors.append(np.linalg.norm(K_sample - test_data.K))  # Computing error wrt the target matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40ee3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix should change\n",
    "matrix_changes = pd.Series(matrix_changes).astype(int)\n",
    "print(\"Matrix changes (1 = changed, 0 = same)\")\n",
    "print(matrix_changes.describe())\n",
    "matrix_changes.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0655fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error should be distributed close to 0 (I guess...)  # BUG https://trello.com/c/9k2e8PQz/33-mcsampleh-is-not-close-to-expected-target\n",
    "errors = pd.Series(errors)\n",
    "print(\"Error metrics\")\n",
    "print(errors.describe())\n",
    "errors.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb26ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f181a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING R weird bug...\n",
    "for j in range(100):\n",
    "    try:\n",
    "        MC_sample_K(G, j, shape_matrix, n_of_samples=1)\n",
    "        print(f'No Exception with {j}')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3096d97f",
   "metadata": {},
   "source": [
    "#### MC_sample_G tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b5c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the function runs with no issues, without side effects\n",
    "W_copy = test_data.W.copy()\n",
    "Z_copy = test_data.Z.copy()\n",
    "H_copy = test_data.H.copy()\n",
    "K_copy = test_data.K.copy()\n",
    "G_copy = random_initial_data.G.copy()\n",
    "E_copy = test_data.E.copy()\n",
    "b = k - 1\n",
    "shape_matrix = np.eye(k)\n",
    "\n",
    "G_sample = MC_sample_G(W_copy, Z_copy, H_copy, K_copy, G_copy, E_copy, b, shape_matrix)\n",
    "\n",
    "assert np.all(W_copy == test_data.W)\n",
    "assert np.all(Z_copy == test_data.Z)\n",
    "assert np.all(H_copy == test_data.H)\n",
    "assert np.all(K_copy == test_data.K)\n",
    "assert np.all(E_copy == test_data.E)\n",
    "assert np.all(shape_matrix == np.eye(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b07684",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Check that the Sampler works properly (This will take... forever)\n",
    "errors = []\n",
    "matrix_changes = []\n",
    "burn_in = 1000\n",
    "for i in range(5000):\n",
    "    G_sample_old = G_sample.copy()\n",
    "    G_sample = MC_sample_G(W_copy, Z_copy, H_copy, K_copy, G_sample, E_copy, b, shape_matrix)\n",
    "    matrix_changes.append(~np.all(G_sample_old == G_sample))\n",
    "    if i >= burn_in:\n",
    "        errors.append(np.linalg.norm(G_sample - test_data.G))  # Computing error wrt the target matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5edd305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix should change  # BUG https://trello.com/c/2K64NaeG/28-mcsampleg-g-matrix-is-never-updated\n",
    "matrix_changes = pd.Series(matrix_changes).astype(int)\n",
    "print(\"Matrix changes (1 = changed, 0 = same)\")\n",
    "print(matrix_changes.describe())\n",
    "matrix_changes.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0072b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error should be distributed close to 0 (I guess...)  # BUG https://trello.com/c/9k2e8PQz/33-mcsampleh-is-not-close-to-expected-target\n",
    "errors = pd.Series(errors)\n",
    "print(\"Error metrics\")\n",
    "print(errors.describe())\n",
    "errors.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b677c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e089fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02fb571b",
   "metadata": {},
   "source": [
    "# MAIN ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7132c254",
   "metadata": {},
   "source": [
    "### Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2b104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_data = Simulator(D, V, M, k, gamma, seed=1984)\n",
    "simulated_data.generate_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9f4712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Data:\n",
    "simulated_data.W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8900b0e4",
   "metadata": {},
   "source": [
    "# SAMPLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aa72ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initial guesses\n",
    "initial = Simulator(D, V, M, k, gamma, 2020)\n",
    "initial.sample_GK()\n",
    "initial.sample_B()\n",
    "initial.sample_H()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a22136",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iteration = 100\n",
    "\n",
    "# Data\n",
    "W = simulated_data.W\n",
    "\n",
    "# Initialization\n",
    "Sigma = initial.Sigma\n",
    "K = np.linalg.inv(Sigma)\n",
    "B = initial.B\n",
    "Theta = initial.Theta\n",
    "G = initial.G\n",
    "\n",
    "alpha = np.ones(V)  # Uninformative prior\n",
    "b = k - 1\n",
    "shape_matrix = np.eye(k)\n",
    "\n",
    "Z = sample_Z_from_W(simulated_data.W.astype(int), k, 2020)  # Random sample of Z based on actual data\n",
    "\n",
    "E = update_E(np.zeros((D, k)), Z)  # Transformation of Z\n",
    "C = update_C(np.zeros((k, V)), Z)  # Transformation of Z\n",
    "\n",
    "\n",
    "for iteration in range(max_iteration):\n",
    "    \n",
    "    # Step 1\n",
    "    Z = MC_sample_Z(Z, W, Theta, B, E, C)\n",
    "    E = update_E(E, Z)  # get E from Z\n",
    "    C = update_C(C, Z)  # get C from Z ...\n",
    "    \n",
    "    # Step 2\n",
    "    B = MC_sample_B(alpha, C)\n",
    "    \n",
    "    # Step 3\n",
    "    H = MC_sample_H(E, Sigma)\n",
    "    Theta = update_Theta(Theta, H)  # get Theta from H\n",
    "    \n",
    "    # Step 4\n",
    "    b += D  # add D since it's the amount of etas we have\n",
    "    shape_matrix += np.matmul(H.T, H)  # Add H^T H (matrix product)\n",
    "    \n",
    "    G_new = MC_sample_G(W, Z, H, K, G, E, b, shape_matrix)\n",
    "    if np.all(G_new == G):\n",
    "        print('G matrix has NOT changed!')\n",
    "    G = G_new\n",
    "    \n",
    "    K = MC_sample_K(G, b, shape_matrix, n_of_samples=1)\n",
    "    Sigma = np.linalg.inv(K)\n",
    "    \n",
    "    # Hope for convergence!\n",
    "    wrong_edges = np.sum(G != simulated_data.G)\n",
    "    error = np.linalg.norm(Sigma - simulated_data.Sigma)\n",
    "    print(f\"At iteration {iteration}, the wrong edges are {wrong_edges} and the error on Sigma is {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff4266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bafc074",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e177810",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08dc207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a803b5bf187bf95155bcb05f6102b06519856e9ee60d4a9ebc29561a74488513"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
