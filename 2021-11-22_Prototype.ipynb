{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "976e9f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES. BE SURE NOT TO OVERWRITE THEM\n",
    "D = 50 # Amount of documents\n",
    "V = 100 # Size of the vocabulary\n",
    "M = 10 # Maximum amount of same word repetition in a document\n",
    "k = 5 # Amount of topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccad145c",
   "metadata": {},
   "source": [
    "## IMPORTANT: Please use static random seeds in **EVERY** cell where you use a random function, so that the result does **NOT** change at every run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3933d68",
   "metadata": {},
   "source": [
    "# 1. ARTIFICIAL DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c874ec5",
   "metadata": {},
   "source": [
    "### Task:\n",
    "\n",
    "You must implement an algorithm that generates an artificial *corpus*, and return also a graph G and a correlation matrix Sigma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e314320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82721e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT:\n",
    "class SIM:  # I'm using a class as a namespace - SIM = Simulation\n",
    "    W = None # matrix of DÃ—V where Wdn is counter of appearances of the word n in document d\n",
    "    Z = None # matrix of DxVxM where Zdnm is the topic index from which the m-th appearance of the word n on doc d is drawn\n",
    "    B = None # matrix of kxV where Bz is the parameter vector of the distribution for the z-th topic\n",
    "    C = None # matrix of kxV where Cz is the count vec of sampled topics over each word for all docs\n",
    "    E = None # matrix of Dxk where Ed is the count vec of sampled drawings for topic z over all words for each doc\n",
    "    H = None # H_d is eta_d\n",
    "    Theta = None  # This is just a transformation of H\n",
    "    G = None  # Adjacency Matrix (Check also python package \"networkx\" for graph objects!)\n",
    "    K = None  # Precision matrix of G\n",
    "    Sigma = None # Inverse of K\n",
    "    \n",
    "    # Remember we will have indexes starting from 0 so all max are -=1\n",
    "    \n",
    "    # Don't know how much these are necessary but\n",
    "    def __init__(D, V, k):\n",
    "        # Create zero matrices for all possible matrices\n",
    "        self.W = np.zeros((D, V))\n",
    "        self.B = np.zeros((k, V))\n",
    "        self.C = np.zeros((k, V))\n",
    "        self.E = np.zeros((D, k))\n",
    "        self.H = np.zeros((D, k))\n",
    "        self.Theta = np.zeros((D, k))\n",
    "        self.G = np.zeros((k, k))\n",
    "        self.K = np.zeros((k, k))\n",
    "        self.Sigma = np.zeros((k, k))\n",
    "        # Z shouldn't be created before W is sampled (depends if generated or read)\n",
    "    \n",
    "    # Generations\n",
    "    def generate_W(self, method, M):\n",
    "        # We use M as the maximum repetitions of words\n",
    "        # Hence, for each word in V in each document, we throw a randint(0,M) for the generative process\n",
    "        if method == 'from_M' and M != 0:\n",
    "            for d in range(D):\n",
    "                for n in range(V):\n",
    "                    self.W[d,n] = np.random.randint(0,M)\n",
    "            print('Success: W generated from M')\n",
    "            return 0\n",
    "        elif method == 'from_Z' and np.sum(self.B, axis=1).sum(axis=0) > 0 and np.sum(self.Z, axis=1).sum(axis=0) > 0 :\n",
    "            # Multinomial drawing from Z, B\n",
    "            # Params: samples (counts), probabilities, repetitions (different vectors)\n",
    "            # np.random.multinomial(1, self.B[Z[d,n,m]], size=1)\n",
    "            # This will give a canonical vector over V\n",
    "            for d in range(D):\n",
    "                for n in range(V):\n",
    "                    for m in range(len(Z[d,n])):\n",
    "                        self.W[d] += np.random.multinomial(1, self.B[Z[d,n,m]], size=1)\n",
    "            print('Success: W generated from Z')\n",
    "            return 0\n",
    "        else\n",
    "            print('Error: Input 0 for the chosen method')\n",
    "            return 1\n",
    "        \n",
    "    def generate_Z(self):\n",
    "        # Multinomial drawing from Theta, because it has to be normalized\n",
    "        # np.random.multinomial(1, self.Theta[d], size=1)\n",
    "        # This will give a canonical vector over k\n",
    "        if np.sum(self.Theta, axis=1).sum(axis=0) == 0:\n",
    "            print('Error: Theta matrix 0')\n",
    "            return 1\n",
    "        for d in range(D):\n",
    "            for n in range(V):\n",
    "                for m in range(self.W[d,n]):\n",
    "                    mult = np.random.multinomial(1, self.Theta[d], size=1)\n",
    "                    self.Z[d,n,m] = np.where(mult == 1)\n",
    "        print('Success: Z generated from Theta')\n",
    "        return 0\n",
    "    \n",
    "    # Transformations\n",
    "    def update_Theta(self):\n",
    "        for d in range(D):\n",
    "            self.Theta[d] = np.exp(self.H[d]) / np.sum(np.exp(self.H[d]), axis=0)\n",
    "        print('Success: Theta transformed from H')\n",
    "        return 0\n",
    "    \n",
    "    def update_E(self):\n",
    "        for topic in range(1, k+1):\n",
    "            E[topic,:] = np.sum(self.Z == topic, axis=2).sum(axis=1)\n",
    "        print('Success: E transformed from Z')\n",
    "        return 0\n",
    "    \n",
    "    def update_C(self):\n",
    "        for topic in range(1, k+1):\n",
    "            self.C[topic, :] = np.sum(self.Z == topic, axis=2).sum(axis=0)\n",
    "        print('Success: C transformed from Z')\n",
    "        return 0\n",
    "        \n",
    "    def update_B(self):\n",
    "        # Note this is the transformation from C\n",
    "        for topic in range(0, k):\n",
    "            self.B[topic] = self.C[topic] / sum(self.C[topic])\n",
    "        print('Success: B transformed from C')\n",
    "        return 0\n",
    "    \n",
    "    def update_Sigma(self):\n",
    "        self.Sigma = np.linalg.inv(self.K)\n",
    "        print('Success: Sigma transformed from K')\n",
    "        return 0\n",
    "    \n",
    "    # Initializing with real data\n",
    "    # def save_W()\n",
    "    \n",
    "    # Priors (Anas)\n",
    "    def sample_B(self, alpha):\n",
    "        # Dirichlet\n",
    "        \n",
    "    def sample_GK(self, gamma):\n",
    "        # Bernoulli for G\n",
    "        # G-Wishart for K given G\n",
    "        update_Sigma()\n",
    "    \n",
    "    def sample_H(self, alpha):\n",
    "        # Multivariate Normal\n",
    "        update_Theta()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "056c90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 1 (Anas):\n",
    "- Beta -> Set some convenient alpha to have an informative sample (maybe needs some playing), get matrix B\n",
    "- G -> Generate the graph to generate K to generate Sigma\n",
    "- Eta -> Matrix H from the multivariate Normal to generate matrix Theta\n",
    "\n",
    "Generate around 3 functions with the following outputs:\n",
    "1. B\n",
    "2. (G, K, Sigma)\n",
    "3. (H, Theta)\n",
    "\n",
    "Step 2 (Francesca):\n",
    "- Matrix Z -> Will come from the multinomial given H/Theta\n",
    "- Matrix W -> Will come from the multinomial given Z, B\n",
    "- Matrices C, E -> Will come from Z\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d26425e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb0c761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4629ce8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b0c6375",
   "metadata": {},
   "source": [
    "### Original Data Generating Algorithm by Kanthavel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "214bfceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "# import numpy.linalg\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adc4879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = [\n",
    "    'dog',\n",
    "    'aunt',\n",
    "    'cat',\n",
    "    'square',\n",
    "    'house',\n",
    "    'root',\n",
    "    'mouse',\n",
    "    'cow',\n",
    "    'palm',\n",
    "    'tree',\n",
    "    'mom',\n",
    "    'sun',\n",
    "    'moon',\n",
    "    'father',\n",
    "    'spoon',\n",
    "    'circle',\n",
    "    'mug',\n",
    "    'glass'\n",
    "]\n",
    "V_arr = np.array(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e0d945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_topic_distribution(seed=1234):\n",
    "    np.random.seed(seed)\n",
    "    vocabulary_size = len(V)\n",
    "    distribution = np.random.random(vocabulary_size)\n",
    "    return distribution / distribution.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af6c63d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01973417, 0.0641021 , 0.04510347, 0.08092336, 0.08036872,\n",
       "       0.02808795, 0.02848688, 0.08262492, 0.0987267 , 0.09025611,\n",
       "       0.0368695 , 0.05162255, 0.07042403, 0.07343683, 0.03815064,\n",
       "       0.05782566, 0.0518377 , 0.0014187 ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_topic_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93f8c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {  # Betas\n",
    "    'red': build_topic_distribution(seed=1),\n",
    "    'blue': build_topic_distribution(seed=2),\n",
    "    'green': build_topic_distribution(seed=3),\n",
    "    'pink': build_topic_distribution(seed=4),\n",
    "    'yellow': build_topic_distribution(seed=5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3da0ac92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.95139825e-02, 1.02798842e-01, 1.63226420e-05, 4.31464413e-02,\n",
       "       2.09438049e-02, 1.31778118e-02, 2.65815397e-02, 4.93156112e-02,\n",
       "       5.66234210e-02, 7.68955339e-02, 5.98240254e-02, 9.77889437e-02,\n",
       "       2.91777592e-02, 1.25317765e-01, 3.90853414e-03, 9.56836599e-02,\n",
       "       5.95543411e-02, 7.97316600e-02])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics['red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9646e2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics['red'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "626a58e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_number = len(topics)\n",
    "topics_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a622911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00775911, 0.2647408 , 0.04999273, 0.427745  , 0.24976236])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1984)\n",
    "topic_mean = np.random.random(len(topics)) \n",
    "topic_mean /= topic_mean.sum()  # Mu\n",
    "topic_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0666ab20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9258647 , 1.32977215, 1.1960876 , 1.02902203, 0.2354462 ],\n",
       "       [1.32977215, 2.59107874, 1.65456663, 1.74944266, 0.87948846],\n",
       "       [1.1960876 , 1.65456663, 2.06661948, 1.5962034 , 0.45713552],\n",
       "       [1.02902203, 1.74944266, 1.5962034 , 1.42787331, 0.61474357],\n",
       "       [0.2354462 , 0.87948846, 0.45713552, 0.61474357, 0.71282345]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(12)\n",
    "topic_covariance = np.random.random((topics_number, topics_number))\n",
    "topic_covariance = np.dot(topic_covariance, topic_covariance.T)\n",
    "topic_covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a74e2c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_proportions(eta):\n",
    "    # Not sure about this\n",
    "    theta = np.exp(eta)\n",
    "    theta /= theta.sum()\n",
    "    return theta.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe690793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th word drawn from topic green is square\n",
      "1-th word drawn from topic green is glass\n",
      "2-th word drawn from topic blue is house\n",
      "3-th word drawn from topic green is tree\n",
      "4-th word drawn from topic green is glass\n",
      "5-th word drawn from topic green is glass\n",
      "6-th word drawn from topic blue is sun\n",
      "7-th word drawn from topic blue is palm\n",
      "8-th word drawn from topic red is father\n",
      "9-th word drawn from topic blue is father\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 2., 0., 0., 0.,\n",
       "       3.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct with this: https://numpy.org/doc/stable/reference/random/index.html#random-quick-start\n",
    "\n",
    "# Building a document:\n",
    "N = 10\n",
    "\n",
    "seed = 1979\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Eta\n",
    "topic_proportions = np.random.multivariate_normal(topic_mean, topic_covariance, 1)  # (in LDA this is a Dirichlet)\n",
    "\n",
    "# Theta\n",
    "topic_normalized_proportions = transform_proportions(topic_proportions)\n",
    "\n",
    "# BoW\n",
    "document = np.zeros(len(V))\n",
    "\n",
    "for n in range(N):\n",
    "    topic_assignment = np.random.multinomial(1, pvals=topic_normalized_proportions).squeeze().astype(bool)\n",
    "    assigned_topic = np.array(list(topics.keys()))[topic_assignment][0]\n",
    "    assigned_topic_distribution = topics[assigned_topic]\n",
    "    word_mask = np.random.multinomial(1, pvals=assigned_topic_distribution).squeeze()\n",
    "    word = V_arr[word_mask.astype(bool)][0]\n",
    "    document += word_mask\n",
    "    print(f'{n}-th word drawn from topic {assigned_topic} is {word}')\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe941847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1b74f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072d3780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96105ee7",
   "metadata": {},
   "source": [
    "# 2 SAMPLER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b9cf8e",
   "metadata": {},
   "source": [
    "# 2.1 Hamiltonian MC Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b11089",
   "metadata": {},
   "source": [
    "### Task:\n",
    "\n",
    "You must implement a function that receives matrices $E_i$, $K_i$ and vector $\\mu$ and generates the next $H_{i+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2168bc86",
   "metadata": {},
   "source": [
    "\n",
    ". $E$ matrix of $D \\times k$ where $E_d$ is the $k$-dim vector of counts of sampled drawings for the $z$-th topic over all words for each document\n",
    "\n",
    ". $K$ matrix of $k \\times k$ representing the precision matrix associated to the graph $G$\n",
    "\n",
    ". $\\mu = 0$\n",
    "\n",
    ". $H$ matrix of $D \\times k$ where $H_d = \\eta_d$ is the $k$-dim vector of the topic prevalences over document $d$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f597bfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing CmdStan version: 2.28.2\n",
      "Install directory: /home/kanthavel/.cmdstan\n",
      "CmdStan version 2.28.2 already installed\n",
      "deleting tmpfiles dir: /tmp/tmppunv_5p8\n",
      "done\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import cmdstanpy\n",
    "# cmdstanpy.install_cmdstan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c2c9cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "os.environ['CMDSTAN'] = '/home/kanthavel/.cmdstan/cmdstan-2.28.2/'\n",
    "from cmdstanpy import cmdstan_path, CmdStanModel\n",
    "\n",
    "import arviz as az\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18cd21df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cmdstanpy:compiling stan program, exe file: /media/kanthavel/data/code/Bayesian_Statistics/Project/multi_normal\n",
      "INFO:cmdstanpy:compiler options: stanc_options=None, cpp_options=None\n",
      "INFO:cmdstanpy:compiled model file: /media/kanthavel/data/code/Bayesian_Statistics/Project/multi_normal\n"
     ]
    }
   ],
   "source": [
    "normal_code = \"\"\"\n",
    "    data {\n",
    "        int<lower=0> dim;\n",
    "        matrix[dim, dim] cov_chol;\n",
    "    }\n",
    "    \n",
    "    parameters {\n",
    "        vector[dim] x;\n",
    "    }\n",
    "    \n",
    "    model {\n",
    "        vector[dim] mu = rep_vector(0, dim);\n",
    "        x ~ multi_normal_cholesky(mu, cov_chol);\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stan_file = \"./multi_normal.stan\"\n",
    "\n",
    "with open(stan_file, \"w\") as f:\n",
    "    print(normal_code, file=f)\n",
    "\n",
    "stan_model = CmdStanModel(stan_file=stan_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7294273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "sigma = 0.99 ** np.abs(np.vstack([np.arange(d)] *d) - np.vstack([np.arange(d)] *d).T)\n",
    "sigma_chol = np.linalg.cholesky(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6799516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cmdstanpy:start chain 1\n",
      "INFO:cmdstanpy:start chain 2\n",
      "INFO:cmdstanpy:start chain 3\n",
      "INFO:cmdstanpy:start chain 4\n",
      "INFO:cmdstanpy:finish chain 1\n",
      "INFO:cmdstanpy:finish chain 3\n",
      "INFO:cmdstanpy:finish chain 2\n",
      "INFO:cmdstanpy:finish chain 4\n"
     ]
    }
   ],
   "source": [
    "normal_data = {\n",
    "    \"dim\": 2,\n",
    "    \"cov_chol\": sigma_chol\n",
    "}\n",
    "\n",
    "stan_fit = stan_model.sample(data=normal_data, chains=4, parallel_chains=4, \n",
    "                             iter_warmup=1000, iter_sampling=5000)\n",
    "\n",
    "cmdstanpy_data = az.from_cmdstanpy(stan_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b49bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_code = \"\"\"\n",
    "    data {\n",
    "        int<lower=0> D;\n",
    "        int<lower=0> k;\n",
    "        matrix[D, k] E;\n",
    "        matrix[k, k] Sigma;\n",
    "        vector[k] mu;\n",
    "    }\n",
    "    \n",
    "    parameters {\n",
    "        matrix[D, k] H;\n",
    "    }\n",
    "    \n",
    "    model {\n",
    "        H ~ normal(mu, Sigma);\n",
    "        matrix[D, k] Theta = ; \n",
    "        E ~ multinomial()...\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9483a770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hamiltonian_MC_Sampling(E, K, mu):\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b18e6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4063d3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b20e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b6e61a0",
   "metadata": {},
   "source": [
    "# 2.2 MCMC Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf4e5d9",
   "metadata": {},
   "source": [
    "### Task:\n",
    "\n",
    "You must implement a function that receives matrices $W$, $\\Theta_{i+1}$ and $B_i$ and generates the next $Z_{i+1}$ and $B_{i+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3f6deae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCMC_Sampling(W, Theta, B):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f673ed09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c762d4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5316331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f9db418",
   "metadata": {},
   "source": [
    "# 2.3 BDMCMC Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce97d80",
   "metadata": {},
   "source": [
    "### Task:\n",
    "\n",
    "You must implement a function that receives matrices $W$, $Z_{i+1}$ and $H_{i+1}$ and generates the next $G_{i+1}$ and $K_{i+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44f63f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BDMCMC_Sampling(W, Z, H):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d85f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dea5bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deff51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5946ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
