{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aaacfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES. BE SURE NOT TO OVERWRITE THEM\n",
    "D = 50 # Amount of documents\n",
    "V = 100 # Size of the vocabulary\n",
    "M = 10 # Maximum amount of same word repetition in a document\n",
    "k = 5 # Amount of topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02f609f",
   "metadata": {},
   "source": [
    "## IMPORTANT: Please use static random seeds in **EVERY** cell where you use a random function, so that the result does **NOT** change at every run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03529ea8",
   "metadata": {},
   "source": [
    "# 1. ARTIFICIAL DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3adecfe",
   "metadata": {},
   "source": [
    "### Task:\n",
    "\n",
    "You must implement an algorithm that generates an artificial *corpus*, and return also a graph G and a correlation matrix Sigma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4b86e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "912fe9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT:\n",
    "class SIM:  # I'm using a class as a namespace - SIM = Simulation\n",
    "    W = None # matrix of DÃ—V where Wdn is counter of appearances of the word n in document d\n",
    "    Z = None # matrix of DxVxM where Zdnm is the topic index from which the m-th appearance of the word n on doc d is drawn\n",
    "    B = None # matrix of kxV where Bz is the parameter vector of the distribution for the z-th topic\n",
    "    C = None # matrix of kxV where Cz is the count vec of sampled topics over each word for all docs\n",
    "    E = None # matrix of Dxk where Ed is the count vec of sampled drawings for topic z over all words for each doc\n",
    "    H = None # H_d is eta_d\n",
    "    Theta = None  # This is just a transformation of H\n",
    "    G = None  # Adjacency Matrix (Check also python package \"networkx\" for graph objects!)\n",
    "    K = None  # Precision matrix of G\n",
    "    Sigma = None # Inverse of K\n",
    "    \n",
    "    # Remember we will have indexes starting from 0 so all max are -=1\n",
    "    \n",
    "    def __init__(D, V, k):\n",
    "        # Create zero matrices for all possible matrices\n",
    "        self.W = np.zeros((D, V))\n",
    "        self.B = np.zeros((k, V))\n",
    "        self.C = np.zeros((k, V))\n",
    "        self.E = np.zeros((D, k))\n",
    "        self.H = np.zeros((D, k))\n",
    "        self.Theta = np.zeros((D, k))\n",
    "        self.G = np.zeros((k, k))\n",
    "        self.K = np.zeros((k, k))\n",
    "        self.Sigma = np.zeros((k, k))\n",
    "        # Z shouldn't be created before W is sampled (depends if generated or read)\n",
    "    \n",
    "    def get_M(self):\n",
    "        # Ref: https://numpy.org/doc/stable/reference/generated/numpy.matrix.max.html\n",
    "        return W.max()\n",
    "    \n",
    "    # Generations\n",
    "    def generate_W_from_M(self, M):\n",
    "        # We use M as the maximum repetitions of words\n",
    "        # Hence, for each word in V in each document, we throw a randint(0,M) for the generative process\n",
    "        if M != 0:\n",
    "            for d in range(D):\n",
    "                for n in range(V):\n",
    "                    self.W[d,n] = np.random.randint(0,M)\n",
    "            print('Success: W generated from M')\n",
    "            return 0\n",
    "        else:\n",
    "            print('Error: Input 0 for the chosen method')\n",
    "            return 1\n",
    "        \n",
    "    def generate_W_from_Z(self):\n",
    "        if np.sum(self.B, axis=1).sum(axis=0) > 0 and np.sum(self.Z, axis=1).sum(axis=0) > 0 :\n",
    "            # Multinomial drawing from Z, B\n",
    "            # Ref https://numpy.org/doc/stable/reference/random/generated/numpy.random.multinomial.html\n",
    "            # Params: samples (counts), probabilities, repetitions (different vectors)\n",
    "            # np.random.multinomial(1, self.B[Z[d,n,m]], size=1)\n",
    "            # This will give a canonical vector over V\n",
    "            for d in range(D):\n",
    "                for n in range(V):\n",
    "                    for m in range(len(Z[d,n])):\n",
    "                        self.W[d] += np.random.multinomial(1, self.B[Z[d,n,m]], size=1)\n",
    "            print('Success: W generated from Z')\n",
    "            return 0\n",
    "        else:\n",
    "            print('Error: Input 0 for the chosen method')\n",
    "            return 1\n",
    "        \n",
    "    def generate_Z(self):\n",
    "        # Multinomial drawing from Theta, because it has to be normalized\n",
    "        # Ref https://numpy.org/doc/stable/reference/random/generated/numpy.random.multinomial.html\n",
    "        # np.random.multinomial(1, self.Theta[d], size=1)\n",
    "        # This will give a canonical vector over k\n",
    "        if np.sum(self.Theta, axis=1).sum(axis=0) == 0:\n",
    "            print('Error: Theta matrix 0')\n",
    "            return 1\n",
    "        for d in range(D):\n",
    "            for n in range(V):\n",
    "                for m in range(self.W[d,n]):\n",
    "                    mult = np.random.multinomial(1, self.Theta[d], size=1)\n",
    "                    self.Z[d,n,m] = np.where(mult == 1)\n",
    "        print('Success: Z generated from Theta')\n",
    "        return 0\n",
    "    \n",
    "    # Transformations\n",
    "    def update_Theta(self):\n",
    "        for d in range(D):\n",
    "            self.Theta[d] = np.exp(self.H[d]) / np.sum(np.exp(self.H[d]), axis=0)\n",
    "        print('Success: Theta transformed from H')\n",
    "        return 0\n",
    "    \n",
    "    def update_E(self):\n",
    "        for topic in range(1, k+1):\n",
    "            E[topic,:] = np.sum(self.Z == topic, axis=2).sum(axis=1)\n",
    "        print('Success: E transformed from Z')\n",
    "        return 0\n",
    "    \n",
    "    def update_C(self):\n",
    "        for topic in range(1, k+1):\n",
    "            self.C[topic, :] = np.sum(self.Z == topic, axis=2).sum(axis=0)\n",
    "        print('Success: C transformed from Z')\n",
    "        return 0\n",
    "        \n",
    "    def update_B(self):\n",
    "        # Note this is the transformation from C\n",
    "        for topic in range(0, k):\n",
    "            self.B[topic] = self.C[topic] / sum(self.C[topic])\n",
    "        print('Success: B transformed from C')\n",
    "        return 0\n",
    "    \n",
    "    def update_Sigma(self):\n",
    "        self.Sigma = np.linalg.inv(self.K)\n",
    "        print('Success: Sigma transformed from K')\n",
    "        return 0\n",
    "    \n",
    "    # Initializing with real data\n",
    "    # def save_W()\n",
    "    \n",
    "    # Priors (Anas)\n",
    "    def build_topic_distribution(seed=1234):\n",
    "        np.random.seed(seed)\n",
    "        vocabulary_size = V\n",
    "        distribution = np.random.random(vocabulary_size)\n",
    "        return distribution / distribution.sum()\n",
    "    \n",
    "    def sample_B(self, alpha):\n",
    "        # B is the matrix whose rows are the distribution of topic i over the vocabulary\n",
    "        # Each row means : for each topic i we have the probability of word i to occur\n",
    "        # Using what Kanthavel did before\n",
    "        b = np.empty((k,V))\n",
    "        \n",
    "        for i in range(k):\n",
    "            b[i,:] = build_topic_distribution(seed=1234)\n",
    "        \n",
    "        self.B = b \n",
    "        return None\n",
    "        \n",
    "    def sample_GK(self, gamma):\n",
    "        # Bernoulli for G\n",
    "        # generate a random adjacency matrix\n",
    "        matrix = np.array([[int(bernoulli.rvs(gamma, size=1)) for i in range(n)] for j in range(n)])\n",
    "        for i in range(n):\n",
    "            matrix[i][i] = 0\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                matrix[j][i] = matrix[i][j]\n",
    "        self.G = matrix\n",
    "        # I can build K for using make_sparse_spd_matrix from sklearn.datasets for example\n",
    "        self.K = make_sparse_spd_matrix(k,alpha=0.95, norm_diag=False, smallest_coef=0.1, largest_coef=0.9, random_state=None)\n",
    "        update_Sigma()\n",
    "    \n",
    "    def sample_H(self, alpha):\n",
    "        # Multivariate Normal\n",
    "        mu = np.zeros(k)\n",
    "        self.H = np.random.multivariate_gaussian(mu,Sigma,k)\n",
    "        update_Theta()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-guest",
   "metadata": {},
   "source": [
    "Step 1 (Anas):\n",
    "- Beta -> Set some convenient alpha to have an informative sample (maybe needs some playing), get matrix B\n",
    "- G -> Generate the graph to generate K to generate Sigma\n",
    "- Eta -> Matrix H from the multivariate Normal to generate matrix Theta\n",
    "\n",
    "Generate around 3 functions with the following outputs:\n",
    "1. B\n",
    "2. (G, K, Sigma)\n",
    "3. (H, Theta)\n",
    "\n",
    "Step 2 (Francesca):\n",
    "- Matrix Z -> Will come from the multinomial given H/Theta\n",
    "- Matrix W -> Will come from the multinomial given Z, B\n",
    "- Matrices C, E -> Will come from Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f859cefb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939e8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38c4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "875912bc",
   "metadata": {},
   "source": [
    "### Original Data Generating Algorithm by Kanthavel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3298eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "# import numpy.linalg\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0df34b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = [\n",
    "    'dog',\n",
    "    'aunt',\n",
    "    'cat',\n",
    "    'square',\n",
    "    'house',\n",
    "    'root',\n",
    "    'mouse',\n",
    "    'cow',\n",
    "    'palm',\n",
    "    'tree',\n",
    "    'mom',\n",
    "    'sun',\n",
    "    'moon',\n",
    "    'father',\n",
    "    'spoon',\n",
    "    'circle',\n",
    "    'mug',\n",
    "    'glass'\n",
    "]\n",
    "V_arr = np.array(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a55f950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_topic_distribution(seed=1234):\n",
    "    np.random.seed(seed)\n",
    "    vocabulary_size = len(V)\n",
    "    distribution = np.random.random(vocabulary_size)\n",
    "    return distribution / distribution.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d07fd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01973417, 0.0641021 , 0.04510347, 0.08092336, 0.08036872,\n",
       "       0.02808795, 0.02848688, 0.08262492, 0.0987267 , 0.09025611,\n",
       "       0.0368695 , 0.05162255, 0.07042403, 0.07343683, 0.03815064,\n",
       "       0.05782566, 0.0518377 , 0.0014187 ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_topic_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1f38df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {  # Betas\n",
    "    'red': build_topic_distribution(seed=1),\n",
    "    'blue': build_topic_distribution(seed=2),\n",
    "    'green': build_topic_distribution(seed=3),\n",
    "    'pink': build_topic_distribution(seed=4),\n",
    "    'yellow': build_topic_distribution(seed=5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c4ad239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.95139825e-02, 1.02798842e-01, 1.63226420e-05, 4.31464413e-02,\n",
       "       2.09438049e-02, 1.31778118e-02, 2.65815397e-02, 4.93156112e-02,\n",
       "       5.66234210e-02, 7.68955339e-02, 5.98240254e-02, 9.77889437e-02,\n",
       "       2.91777592e-02, 1.25317765e-01, 3.90853414e-03, 9.56836599e-02,\n",
       "       5.95543411e-02, 7.97316600e-02])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics['red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9d8e4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics['red'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb502a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_number = len(topics)\n",
    "topics_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "818d3c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00775911, 0.2647408 , 0.04999273, 0.427745  , 0.24976236])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1984)\n",
    "topic_mean = np.random.random(len(topics)) \n",
    "topic_mean /= topic_mean.sum()  # Mu\n",
    "topic_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0e8588c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9258647 , 1.32977215, 1.1960876 , 1.02902203, 0.2354462 ],\n",
       "       [1.32977215, 2.59107874, 1.65456663, 1.74944266, 0.87948846],\n",
       "       [1.1960876 , 1.65456663, 2.06661948, 1.5962034 , 0.45713552],\n",
       "       [1.02902203, 1.74944266, 1.5962034 , 1.42787331, 0.61474357],\n",
       "       [0.2354462 , 0.87948846, 0.45713552, 0.61474357, 0.71282345]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(12)\n",
    "topic_covariance = np.random.random((topics_number, topics_number))\n",
    "topic_covariance = np.dot(topic_covariance, topic_covariance.T)\n",
    "topic_covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b61ecc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_proportions(eta):\n",
    "    # Not sure about this\n",
    "    theta = np.exp(eta)\n",
    "    theta /= theta.sum()\n",
    "    return theta.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "856c1242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th word drawn from topic yellow is spoon\n",
      "1-th word drawn from topic yellow is mouse\n",
      "2-th word drawn from topic blue is tree\n",
      "3-th word drawn from topic blue is cat\n",
      "4-th word drawn from topic green is moon\n",
      "5-th word drawn from topic blue is mug\n",
      "6-th word drawn from topic pink is circle\n",
      "7-th word drawn from topic green is dog\n",
      "8-th word drawn from topic pink is circle\n",
      "9-th word drawn from topic green is sun\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 2., 1.,\n",
       "       0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct with this: https://numpy.org/doc/stable/reference/random/index.html#random-quick-start\n",
    "\n",
    "# Building a document:\n",
    "N = 10\n",
    "\n",
    "seed = 1979\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Eta\n",
    "topic_proportions = np.random.multivariate_normal(topic_mean, topic_covariance, 1)  # (in LDA this is a Dirichlet)\n",
    "\n",
    "# Theta\n",
    "topic_normalized_proportions = transform_proportions(topic_proportions)\n",
    "\n",
    "# BoW\n",
    "document = np.zeros(len(V))\n",
    "\n",
    "for n in range(N):\n",
    "    topic_assignment = np.random.multinomial(1, pvals=topic_normalized_proportions).squeeze().astype(bool)\n",
    "    assigned_topic = np.array(list(topics.keys()))[topic_assignment][0]\n",
    "    assigned_topic_distribution = topics[assigned_topic]\n",
    "    word_mask = np.random.multinomial(1, pvals=assigned_topic_distribution).squeeze()\n",
    "    word = V_arr[word_mask.astype(bool)][0]\n",
    "    document += word_mask\n",
    "    print(f'{n}-th word drawn from topic {assigned_topic} is {word}')\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca68f855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfde0afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce53b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fafa4ff",
   "metadata": {},
   "source": [
    "# 2 SAMPLER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963c978d",
   "metadata": {},
   "source": [
    "# 2.1 Hamiltonian MC Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a859613d",
   "metadata": {},
   "source": [
    "### Task:\n",
    "\n",
    "You must implement a function that receives matrices $E_i$, $K_i$ and vector $\\mu$ and generates the next $H_{i+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcae07f",
   "metadata": {},
   "source": [
    "\n",
    ". $E$ matrix of $D \\times k$ where $E_d$ is the $k$-dim vector of counts of sampled drawings for the $z$-th topic over all words for each document\n",
    "\n",
    ". $K$ matrix of $k \\times k$ representing the precision matrix associated to the graph $G$\n",
    "\n",
    ". $\\mu = 0$\n",
    "\n",
    ". $H$ matrix of $D \\times k$ where $H_d = \\eta_d$ is the $k$-dim vector of the topic prevalences over document $d$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82d509f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a838008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampled_distribution_kernel(eta, K, E):\n",
    "    k = eta.shape[0]\n",
    "    eta_K_eta = -0.5 * eta.dot(K.dot(eta))\n",
    "    E_eta = E.dot(eta)\n",
    "    sum_eta_pow_k = np.sum(np.exp(eta)) ** k\n",
    "    return np.exp(eta_K_eta + E_eta) / sum_eta_pow_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21626879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_sampler(E, Sigma, H_current=None, burn_in=100, seed=None):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    K = np.linalg.inv(Sigma)\n",
    "    \n",
    "    D, k = E.shape  # Number of documents, Number of topics\n",
    "    \n",
    "    if H_current is None:\n",
    "        H_current = np.zeros((D, k))\n",
    "    \n",
    "    H_sampled = np.zeros((D, k))\n",
    "    \n",
    "    for d in range(D):  # Iterating over each document\n",
    "        eta_current = H_current[d]\n",
    "        E_d = E[d]\n",
    "        for iteration in range(burn_in + 1):\n",
    "            \n",
    "            # Sampling proposed eta from multivariate normal (q \"proposal density\")\n",
    "            eta_prop = np.random.multivariate_normal(eta_current, Sigma)\n",
    "            \n",
    "            # Compute acceptance probability\n",
    "            alpha = min(1, sampled_distribution_kernel(eta_prop, K, E_d) / sampled_distribution_kernel(eta_current, K, E_d))\n",
    "            \n",
    "            if alpha == 1 or np.random.uniform(0.0, 1.0) < alpha:\n",
    "                eta_current = eta_prop\n",
    "            \n",
    "        H_sampled[d] = eta_current\n",
    "    \n",
    "    return H_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093e9f07",
   "metadata": {},
   "source": [
    "# 2.2 MCMC Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a32afa8",
   "metadata": {},
   "source": [
    "### Task:\n",
    "\n",
    "You must implement a function that receives matrices $W$, $\\Theta_{i+1}$ and $B_i$ and generates the next $Z_{i+1}$ and $B_{i+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c0fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCMC_Sampling(W, Theta, B):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e828c074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004fcf94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a37b5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e28b2a1b",
   "metadata": {},
   "source": [
    "# 2.3 BDMCMC Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b898ef11",
   "metadata": {},
   "source": [
    "### Task:\n",
    "\n",
    "You must implement a function that receives matrices $W$, $Z_{i+1}$ and $H_{i+1}$ and generates the next $G_{i+1}$ and $K_{i+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed4170cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BDMCMC_Sampling(W, Z, H):\n",
    "    #update_G(W,Z,H,K,G)\n",
    "    #update_K()\n",
    "    return (G,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "804013e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.05\n",
    "\n",
    "def update_G(W, Z, H, K, G):\n",
    "\n",
    "    N = G.shape[0]\n",
    "    delta_K = 0\n",
    "    beta_K = 0\n",
    "\n",
    "    death_rates = np.zeros((k,k))\n",
    "    birth_rates = np.zeros((k,k))\n",
    "\n",
    "    PrHK = lambda K,H:      K.size**(n/2) * np.exp(-0.5*np.trace(np.matmul(np.matmul(K, np.transpose(H)), H)))\n",
    "    PrK_G = lambda K,G,D,b: K.size**(b+D-2) * np.exp(-0.5*np.trace(np.matmul(S + np.matmul(np.transpose(H), H), K)))\n",
    "    PrG = lambda gamma, E:  (gamma/(1-gamma))**(E.size)\n",
    "\n",
    "    PrKG_H = lambda K,G,H,D,b,gamma,E: PrHK(K,H)*PrK_G(K,G,D,b)*PrG(gamma,E)\n",
    "\n",
    "    Pr_init = PrKG_H(K,G,H,D,b,gamma,E)\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "            if G[i,j]:\n",
    "                G_loop = G.copy()\n",
    "                G_loop[i,j], G_loop[j,i] = 0\n",
    "                #technically, we should compute K_loop here...\n",
    "                Pr_loop = PrKG_H(K,G_loop,H,D,b,gamma,E)\n",
    "\n",
    "                death_rate = Pr_loop/Pr_init\n",
    "\n",
    "                if death_rate > 1:\n",
    "                    death_rate = 1\n",
    "                death_rates[i,j], death_rates[j,i] = death_rate, death_rate\n",
    "                delta_K += death_rate\n",
    "\n",
    "            else:\n",
    "                G_loop = G.copy()\n",
    "                G_loop[i,j], G_loop[j,i] = 1\n",
    "                #technically, we should compute K_loop here...\n",
    "                Pr_loop = PrKG_H(K,G_loop,H,D,b,gamma,E) \n",
    "\n",
    "                birth_rate = Pr_loop/Pr_init\n",
    "\n",
    "                if birth_rate > 1:\n",
    "                    birth_rate = 1\n",
    "                birth_rates[i,j], birth_rates[j,i] = birth_rate, birth_rate\n",
    "                beta_K += birth_rate\n",
    "    \n",
    "    W = 1/(beta_K + delta_K)\n",
    "\n",
    "    pr_death = W*death_rates\n",
    "    pr_birth = W*birth_rates\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "            if pr_death[i,j] > 0.5:\n",
    "                G[i,j], G[j,i] = 0,0\n",
    "            elif pr_birth[i,j] > 0.5:\n",
    "                G[i,j], G[j,i] = 1,1\n",
    "\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e64083b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe564c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011866c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a803b5bf187bf95155bcb05f6102b06519856e9ee60d4a9ebc29561a74488513"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
